# Requisitos:
# pip install chromadb sentence-transformers pyodbc google-generativeai pandas python-dotenv sqlalchemy

import chromadb
from chromadb.utils import embedding_functions
import pyodbc
import google.generativeai as genai
import pandas as pd
import os
import datetime
from dotenv import load_dotenv
import time
from sqlalchemy import create_engine
import json

# ==============================================================================
# üîπ NOVO SCRIPT COM SUGEST√ïES IMPLEMENTADAS
# ==============================================================================
#
# Principais Altera√ß√µes:
# 1. METADADOS ENRIQUECIDOS: Os schemas das tabelas agora s√£o muito mais
#    detalhados, incluindo tipos de dados, exemplos e, crucialmente,
#    instru√ß√µes expl√≠citas de RELACIONAMENTO para guiar a cria√ß√£o de JOINs.
#
# 2. CACHE SEM√ÇNTICO: A pipeline agora verifica se uma pergunta muito similar
#    j√° foi feita. Se sim, reutiliza o SQL gerado anteriormente para economizar
#    tempo e custos de API.
#
# 3. CAMADA DE SEGURAN√áA: Uma nova fun√ß√£o `generate_safe_sql` foi adicionada
#    para bloquear comandos SQL perigosos (UPDATE, DELETE) e para adicionar
#    automaticamente um `TOP 1000` a todas as consultas, prevenindo sobrecarga.
#
# 4. PROMPT OTIMIZADO: O prompt enviado ao Gemini foi reestruturado com tags
#    para melhorar a clareza e a precis√£o da gera√ß√£o de SQL.
#
# ==============================================================================


# ===========================
# üîπ CONFIGURA√á√ïES INICIAIS
# ===========================

load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("Defina GEMINI_API_KEY no .env ou como vari√°vel de ambiente!")

genai.configure(api_key=GEMINI_API_KEY)
MODEL = genai.GenerativeModel(
    "gemini-2.5-flash",
    generation_config=genai.types.GenerationConfig(
        max_output_tokens=2048,
        temperature=0.1
    )
)

SERVER = "EMILYNICOLE"
DATABASE = "datasets"
engine_str = f"mssql+pyodbc://@{SERVER}/{DATABASE}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes"
engine = create_engine(engine_str)

client = chromadb.PersistentClient(path="./chroma_db")

embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name="modelos/all-MiniLM-L6-v2"
)

collection = client.get_or_create_collection(
    name="schema_collection_v3_enriched", # Nova vers√£o da cole√ß√£o
    embedding_function=embedding_fn
)
history_collection = client.get_or_create_collection(
    name="history_collection_v3",
    embedding_function=embedding_fn
)

# ==============================================================================
# üîπ ENRIQUECIMENTO DE METADADOS: SCHEMAS DAS TABELAS (NOVO FORMATO)
# ==============================================================================

# Para demonstrar JOINs, criamos uma segunda tabela hipot√©tica: CadastroOperadoras
schema_documents = [
    {
        "id": "table_TabelaOriginal",
        "content": """
        Tabela: TabelaOriginal. 
        Descri√ß√£o: Tabela principal (fato) que registra cada entrega de um modelo em um pa√≠s. Use esta tabela para perguntas sobre quantidades, datas e status.
        Colunas: 
        - Modelo (TEXTO): O nome do modelo do item entregue. Ex: 'ModeloX', 'ProdutoY'.
        - Pa√≠s (TEXTO): O pa√≠s de destino da entrega. Mapeie nomes em portugu√™s para ingl√™s (ex: Brasil -> 'Brazil', Fran√ßa -> 'France').
        - Data_Entrega (DATA): A data exata em que a entrega foi realizada. Use fun√ß√µes como YEAR() e MONTH() para agregar por per√≠odo.
        - Status (TEXTO): A situa√ß√£o atual da entrega. Valores comuns: 'Done', 'Completed', 'Analysis'.
        - id_operadora (INTEIRO): Chave estrangeira que identifica a operadora. Use esta coluna para conectar com a tabela 'CadastroOperadoras'.
        
        RELACIONAMENTOS:
        - Para saber o NOME da operadora, fa√ßa um JOIN com a tabela 'CadastroOperadoras' usando: TabelaOriginal.id_operadora = CadastroOperadoras.id.
        """
    },
    {
        "id": "table_CadastroOperadoras",
        "content": """
        Tabela: CadastroOperadoras.
        Descri√ß√£o: Tabela de cadastro (dimens√£o) com os nomes das operadoras de log√≠stica.
        Colunas:
        - id (INTEIRO): Chave prim√°ria √∫nica da operadora.
        - nome_operadora (TEXTO): O nome comercial da operadora. Ex: 'LogiFast', 'RapidTrans', 'EntregaGlobal'.
        
        RELACIONAMENTOS:
        - Esta tabela se conecta √† 'TabelaOriginal' pela coluna 'id'. Use-a para buscar o nome da operadora a partir de um 'id_operadora'.
        """
    },
    {
        "id": "table_GraduateEmployment",
        "content": """
        Tabela: GraduateEmployment.
        Descri√ß√£o: Cont√©m dados anuais sobre o emprego de graduados em Singapura, incluindo taxas de emprego e sal√°rios por universidade e curso.
        Colunas:
        - year (INTEIRO): Ano da pesquisa.
        - university (TEXTO): Nome da universidade.
        - degree (TEXTO): Nome do curso/gradua√ß√£o.
        - employment_rate_overall (NUM√âRICO): Taxa de emprego geral (de 0 a 100).
        - basic_monthly_mean (NUM√âRICO): Sal√°rio mensal b√°sico m√©dio.
        - gross_monthly_median (NUM√âRICO): Mediana do sal√°rio mensal bruto.
        """
    }
]

# ===========================
# üîπ POPULAR SCHEMA (execute uma vez)
# ===========================

def populate_chroma():
    existing = collection.count()
    if existing > 0:
        print(f"‚ö†Ô∏è ChromaDB (schema) j√° possui {existing} documentos. Pular popula√ß√£o.")
        return

    documents = [doc["content"] for doc in schema_documents]
    ids = [doc["id"] for doc in schema_documents]

    collection.add(documents=documents, ids=ids)
    print("‚úÖ Schemas enriquecidos adicionados ao ChromaDB.")

# ==============================================================================
# üîπ CONSULTA RAG COM CACHE SEM√ÇNTICO
# ==============================================================================

def query_rag_with_cache(user_question, n_results=3, cache_threshold=0.15):
    # Passo 1: Buscar no hist√≥rico por uma pergunta muito similar para usar como cache
    history_results = history_collection.query(
        query_texts=[user_question],
        n_results=1,
        include=["documents", "distances"]  # Importante: pedir as dist√¢ncias
    )

    cached_sql = None
    # Verifica√ß√£o segura: se h√° documentos e dist√¢ncias v√°lidas
    if (history_results["documents"] and 
        len(history_results["documents"][0]) > 0 and 
        history_results["distances"] and 
        len(history_results["distances"][0]) > 0 and 
        history_results["distances"][0][0] < cache_threshold):
        print(f"üîç Encontrada pergunta similar no hist√≥rico (dist√¢ncia: {history_results['distances'][0][0]:.3f}). Ativando cache.")
        history_doc = history_results["documents"][0][0]
        # Extrai o SQL do documento de hist√≥rico
        if "SQL:" in history_doc:
            cached_sql = history_doc.split("SQL:")[1].split("\n")[0].strip()
            # Retornamos o SQL do cache e pulamos o resto da busca de contexto
            return "", cached_sql

    # Passo 2: Se n√£o h√° cache, buscar contexto do schema e do hist√≥rico para gerar um novo SQL
    schema_results = collection.query(query_texts=[user_question], n_results=n_results)
    schema_relevant = "\n".join(schema_results["documents"][0]) if schema_results["documents"] else ""

    history_context_docs = history_collection.query(query_texts=[user_question], n_results=1)
    history_relevant = "\n".join(history_context_docs["documents"][0]) if history_context_docs["documents"] else "Nenhum hist√≥rico relevante."

    full_context = f"Schema relevante:\n{schema_relevant}\n\nExemplo de pergunta/SQL recente:\n{history_relevant}"
    return full_context, None # Retorna o contexto completo e None para o cache

# ==============================================================================
# üîπ GERAR SQL VIA GEMINI (COM PROMPT OTIMIZADO)
# ==============================================================================

def generate_sql(user_question, relevant_context):
    prompt = f"""
    Voc√™ √© um especialista em gerar c√≥digo T-SQL para SQL Server.
    Sua tarefa √© gerar uma √öNICA query SQL v√°lida baseada na pergunta do usu√°rio e no contexto do schema fornecido.

    <instru√ß√µes>
    1.  Use APENAS as tabelas e colunas descritas no contexto.
    2.  Preste aten√ß√£o especial √†s se√ß√µes de RELACIONAMENTOS para criar JOINs corretos quando necess√°rio.
    3.  Mapeie nomes em portugu√™s para seus equivalentes em ingl√™s (ex: Fran√ßa -> 'France', Brasil -> 'Brazil').
    4.  Responda APENAS com o c√≥digo SQL, sem explica√ß√µes, coment√°rios ou formata√ß√£o ```sql.
    </instru√ß√µes>

    <contexto_schema>
    {relevant_context}
    </contexto_schema>

    <pergunta_usuario>
    {user_question}
    </pergunta_usuario>

    SQL Gerado:
    """

    try:
        response = MODEL.generate_content(prompt)
        sql_query = response.text.strip()
        # Limpeza final para remover markdown que o modelo √†s vezes insiste em adicionar
        if sql_query.startswith("```sql"):
            sql_query = sql_query[6:]
        if sql_query.endswith("```"):
            sql_query = sql_query[:-3]
        return sql_query.strip()
    except Exception as e:
        print(f"‚ùå Erro na API Gemini (generate_sql): {str(e)}")
        return "SELECT 'Erro ao gerar SQL' AS Error;"

# ==============================================================================
# üîπ NOVA CAMADA DE SEGURAN√áA PARA SQL
# ==============================================================================

def generate_safe_sql(user_question, relevant_context):
    raw_sql = generate_sql(user_question, relevant_context)

    # Regra 1: Bloquear palavras-chave perigosas
    forbidden_keywords = ["DROP", "DELETE", "UPDATE", "INSERT", "TRUNCATE", "ALTER", "CREATE", "EXEC"]
    for keyword in forbidden_keywords:
        if keyword in raw_sql.upper():
            print(f"‚ö†Ô∏è ALERTA DE SEGURAN√áA: SQL bloqueado por conter '{keyword}': {raw_sql}")
            return "SELECT 'Comando n√£o permitido detectado. Apenas consultas SELECT s√£o autorizadas.' AS SecurityError;"

    # Regra 2: For√ßar um limite de resultados (TOP para SQL Server) se n√£o houver um
    if "SELECT" in raw_sql.upper() and "LIMIT" not in raw_sql.upper() and "TOP" not in raw_sql.upper():
        # Adiciona TOP 1000 ap√≥s o primeiro SELECT
        raw_sql = raw_sql.replace("SELECT", "SELECT TOP 1000", 1)
        print("üõ°Ô∏è Adicionado 'TOP 1000' por seguran√ßa √† query.")

    return raw_sql


# ===========================
# üîπ EXECUTAR SQL LOCALMENTE (sem altera√ß√µes)
# ===========================
def execute_sql(sql_query):
    try:
        df = pd.read_sql(sql_query, engine)
        if len(df) > 50:
             json_results = df.head(50).to_json(orient='records', indent=2) + f"\n... (resultados truncados, mostrando 50 de {len(df)} registros)"
        else:
             json_results = df.to_json(orient='records', indent=2)
        return json_results
    except Exception as e:
        return json.dumps({"error": str(e)}, indent=2)


# ===========================
# üîπ TRATAR RESPOSTA COM GEMINI (sem altera√ß√µes)
# ===========================
def treat_response(sql_results, user_question):
    if len(sql_results) > 1500:
        sql_results = sql_results[:1500] + "\n... (dados truncados)"

    prompt = f"""
    Com base nos seguintes dados em formato JSON, responda √† pergunta do usu√°rio de forma clara e concisa em portugu√™s.
    - Se os dados forem uma lista, resuma os principais pontos ou os top 5 resultados.
    - Se houver uma mensagem de erro, explique o erro de forma amig√°vel.
    - N√£o mencione que os dados vieram de um JSON ou SQL. Apenas apresente a resposta.

    <dados_json>
    {sql_results}
    </dados_json>

    <pergunta_original>
    {user_question}
    </pergunta_original>

    Resposta final:
    """
    try:
        response = MODEL.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print(f"‚ùå Erro na API Gemini (treat_response): {str(e)}")
        return f"Houve um problema ao processar os resultados. Dados brutos: {sql_results}"


# ===========================
# üîπ ARMAZENAR HIST√ìRICO
# ===========================
def store_history(user_question, sql_query):
    # N√£o precisamos mais salvar os resultados e a resposta, apenas o par pergunta/SQL
    history_doc = f"Pergunta: {user_question}\nSQL: {sql_query}"
    history_id = f"query_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
    history_collection.add(documents=[history_doc], ids=[history_id])
    print(f"üß† Hist√≥rico salvo (ID: {history_id})")

# ===========================
# üîπ FUN√á√ÉO AUXILIAR PARA MEDIR TEMPO
# ===========================
def time_it(func, *args, **kwargs):
    start = time.perf_counter()
    result = func(*args, **kwargs)
    elapsed = time.perf_counter() - start
    print(f"‚è±Ô∏è  {func.__name__:<25} levou {elapsed:.2f}s")
    return result

# ==============================================================================
# üîπ PIPELINE PRINCIPAL RAG (ATUALIZADA)
# ==============================================================================

def rag_pipeline(user_question):
    print("\n" + "="*50)
    print(f"üöÄ Iniciando pipeline para a pergunta: '{user_question}'")
    print("="*50)

    # 1. Consultar RAG e verificar cache
    relevant_context, cached_sql = time_it(query_rag_with_cache, user_question)

    if cached_sql:
        print("‚ö° Cache Sem√¢ntico Ativado! Reutilizando SQL.")
        sql_query = cached_sql
    else:
        print("üß† Cache n√£o ativado. Gerando novo SQL com seguran√ßa.")
        # 2. Gerar SQL de forma segura
        sql_query = time_it(generate_safe_sql, user_question, relevant_context)

    print(f"üí¨ SQL a ser executado: {sql_query}")

    # 3. Executar SQL
    results = time_it(execute_sql, sql_query)
    
    # 4. Tratar resposta para o usu√°rio
    final_answer = time_it(treat_response, results, user_question)

    # 5. Salvar no hist√≥rico apenas se a query for nova
    if not cached_sql and "Error" not in sql_query:
        time_it(store_history, user_question, sql_query)
    
    return final_answer

# ===========================
# üîπ EXECU√á√ÉO DE EXEMPLO
# ===========================

if __name__ == "__main__":
    # Primeira execu√ß√£o ir√° popular o ChromaDB com os novos schemas
    populate_chroma()

    # --- TESTE 1: Pergunta que requer um JOIN ---
    # O sistema deve usar os metadados enriquecidos para juntar TabelaOriginal com CadastroOperadoras
    question1 = "Quais os 5 modelos mais entregues pela operadora Movistar no Brasil?"
    answer1 = rag_pipeline(question1)
    print(f"\n‚úÖ Resposta Final 1:\n{answer1}")

    # --- TESTE 2: Pergunta simples sobre outra tabela ---
    question2 = "Qual universidade teve a maior m√©dia de notas em 2013?"
    answer2 = rag_pipeline(question2)
    print(f"\n‚úÖ Resposta Final 2:\n{answer2}")
    
    # --- TESTE 3: Repetir uma pergunta similar para testar o CACHE SEM√ÇNTICO ---
    # A pipeline deve detectar a similaridade e reutilizar o SQL da pergunta 2
    question3 = "qual a universidade com maior desempenho em 2019?"
    answer3 = rag_pipeline(question3)
    print(f"\n‚úÖ Resposta Final 3 (do cache):\n{answer3}")