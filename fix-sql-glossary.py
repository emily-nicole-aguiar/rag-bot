# Requisitos:
# pip install chromadb sentence-transformers pyodbc google-generativeai pandas python-dotenv sqlalchemy

import chromadb
from chromadb.utils import embedding_functions
import pyodbc
import google.generativeai as genai
import pandas as pd
import os
import datetime
from dotenv import load_dotenv
import time
from sqlalchemy import create_engine
import json

# ==============================================================================
# üîπ NOVO SCRIPT COM SUGEST√ïES IMPLEMENTADAS (v2)
# ==============================================================================
#
# Principais Altera√ß√µes:
# 1. LOOP DE AUTO-CORRE√á√ÉO (NOVO): Se a execu√ß√£o do SQL falhar, a pipeline
#    captura a mensagem de erro e pede ao LLM para corrigir o SQL.
#    Isso √© feito na `rag_pipeline` e `generate_sql`.
#
# 2. GLOSS√ÅRIO NA RESPOSTA (NOVO): O contexto do schema (gloss√°rio) buscado
#    no RAG √© agora passado para a fun√ß√£o `treat_response` para que a
#    explica√ß√£o final ao usu√°rio seja mais precisa e rica em contexto.
#
# 3. MUDAN√áAS DE FUN√á√ÉO:
#    - `execute_sql` agora retorna (resultado, erro) para controle.
#    - `generate_sql` aceita `failed_sql` e `error_message` para corre√ß√£o.
#    - `query_rag_with_cache` foi otimizado para sempre retornar o
#      contexto do schema, mesmo quando o cache √© ativado.
#    - `rag_pipeline` orquestra o novo loop de corre√ß√£o.
#
# ==============================================================================


# ===========================
# üîπ CONFIGURA√á√ïES INICIAIS
# ===========================

load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("Defina GEMINI_API_KEY no .env ou como vari√°vel de ambiente!")

genai.configure(api_key=GEMINI_API_KEY)
MODEL = genai.GenerativeModel(
    "gemini-1.5-flash",
    generation_config=genai.types.GenerationConfig(
        max_output_tokens=2048,
        temperature=0.1
    )
)

SERVER = "EMILYNICOLE"
DATABASE = "datasets"
engine_str = f"mssql+pyodbc://@{SERVER}/{DATABASE}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes"
engine = create_engine(engine_str)

client = chromadb.PersistentClient(path="./chroma_db")

embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name="modelos/all-MiniLM-L6-v2"
)

collection = client.get_or_create_collection(
    name="schema_collection_v3_enriched",
    embedding_function=embedding_fn
)
history_collection = client.get_or_create_collection(
    name="history_collection_v3",
    embedding_function=embedding_fn
)

# ===========================
# üîπ SCHEMAS DAS TABELAS
# ===========================

# (Schemas enriquecidos mantidos da vers√£o anterior)
schema_documents = [
    {
        "id": "table_TabelaOriginal",
        "content": """
        Tabela: TabelaOriginal. 
        Descri√ß√£o: Tabela principal (fato) que registra cada entrega de um modelo em um pa√≠s. Use esta tabela para perguntas sobre quantidades, datas e status.
        Colunas: 
        - Modelo (TEXTO): O nome do modelo do item entregue. Ex: 'ModeloX', 'ProdutoY'.
        - Pa√≠s (TEXTO): O pa√≠s de destino da entrega. Mapeie nomes em portugu√™s para ingl√™s (ex: Brasil -> 'Brazil', Fran√ßa -> 'France').
        - Data_Entrega (DATA): A data exata em que a entrega foi realizada. Use fun√ß√µes como YEAR() e MONTH() para agregar por per√≠odo.
        - Status (TEXTO): A situa√ß√£o atual da entrega. Valores comuns: 'Done', 'Completed', 'Analysis'.
        - id_operadora (INTEIRO): Chave estrangeira que identifica a operadora. Use esta coluna para conectar com a tabela 'CadastroOperadoras'.
        
        RELACIONAMENTOS:
        - Para saber o NOME da operadora, fa√ßa um JOIN com a tabela 'CadastroOperadoras' usando: TabelaOriginal.id_operadora = CadastroOperadoras.id.
        """
    },
    {
        "id": "table_CadastroOperadoras",
        "content": """
        Tabela: CadastroOperadoras.
        Descri√ß√£o: Tabela de cadastro (dimens√£o) com os nomes das operadoras de log√≠stica.
        Colunas:
        - id (INTEIRO): Chave prim√°ria √∫nica da operadora.
        - nome_operadora (TEXTO): O nome comercial da operadora. Ex: 'LogiFast', 'RapidTrans', 'EntregaGlobal'.
        
        RELACIONAMENTOS:
        - Esta tabela se conecta √† 'TabelaOriginal' pela coluna 'id'. Use-a para buscar o nome da operadora a partir de um 'id_operadora'.
        """
    },
    {
        "id": "table_GraduateEmployment",
        "content": """
        Tabela: GraduateEmployment.
        Descri√ß√£o: Cont√©m dados anuais sobre o emprego de graduados em Singapura, incluindo taxas de emprego e sal√°rios por universidade e curso.
        Colunas:
        - year (INTEIRO): Ano da pesquisa.
        - university (TEXTO): Nome da universidade.
        - degree (TEXTO): Nome do curso/gradua√ß√£o.
        - employment_rate_overall (NUM√âRICO): Taxa de emprego geral (de 0 a 100).
        - basic_monthly_mean (NUM√âRICO): Sal√°rio mensal b√°sico m√©dio.
        - gross_monthly_median (NUM√âRICO): Mediana do sal√°rio mensal bruto.
        """
    }
]

# ===========================
# üîπ POPULAR SCHEMA
# ===========================

def populate_chroma():
    existing = collection.count()
    if existing > 0:
        print(f"‚ö†Ô∏è ChromaDB (schema) j√° possui {existing} documentos. Pular popula√ß√£o.")
        return

    documents = [doc["content"] for doc in schema_documents]
    ids = [doc["id"] for doc in schema_documents]

    collection.add(documents=documents, ids=ids)
    print("‚úÖ Schemas enriquecidos adicionados ao ChromaDB.")

# ==============================================================================
# üîπ CONSULTA RAG (OTIMIZADA PARA SEMPRE RETORNAR SCHEMA)
# ==============================================================================

def query_rag_with_cache(user_question, n_results=3, cache_threshold=0.15):
    # Passo 1: Buscar SEMPRE o contexto do schema.
    # Isso √© necess√°rio para o "Gloss√°rio" na etapa final.
    schema_results = collection.query(query_texts=[user_question], n_results=n_results)
    schema_relevant = "\n".join(schema_results["documents"][0]) if schema_results["documents"] else ""

    # Passo 2: Buscar no hist√≥rico para tentar o cache.
    history_results = history_collection.query(
        query_texts=[user_question],
        n_results=1,
        include=["documents", "distances"]
    )

    cached_sql = None
    # Se encontramos um resultado e a dist√¢ncia √© muito pequena (alta similaridade)...
    if history_results["documents"] and history_results["distances"][0][0] < cache_threshold:
        print(f"üîç Encontrada pergunta similar no hist√≥rico (dist√¢ncia: {history_results['distances'][0][0]:.3f}). Ativando cache.")
        history_doc = history_results["documents"][0][0]
        if "SQL:" in history_doc:
            cached_sql = history_doc.split("SQL:")[1].split("\n")[0].strip()
            # Retornamos o schema (para o gloss√°rio) e o SQL do cache
            return schema_relevant, cached_sql

    # Passo 3: Se n√£o h√° cache, montar o contexto completo (schema + hist√≥rico)
    history_context_docs = history_results["documents"][0] if history_results["documents"] else []
    history_relevant = "\n".join(history_context_docs) if history_context_docs else "Nenhum hist√≥rico relevante."
    
    full_context = f"Schema relevante:\n{schema_relevant}\n\nExemplo de pergunta/SQL recente:\n{history_relevant}"
    
    return full_context, None # Retorna o contexto completo e None para o cache

# ==============================================================================
# üîπ GERAR SQL (ATUALIZADO PARA AUTO-CORRE√á√ÉO)
# ==============================================================================

def generate_sql(user_question, relevant_context, failed_sql=None, error_message=None):
    
    # Se failed_sql for fornecido, o modo √© "CORRE√á√ÉO"
    if failed_sql:
        prompt = f"""
        Voc√™ √© um especialista em corrigir T-SQL para SQL Server.
        A query anterior falhou. Por favor, corrija-a.

        <contexto_schema>
        {relevant_context}
        </contexto_schema>

        <query_com_erro>
        {failed_sql}
        </query_com_erro>

        <mensagem_de_erro_sql>
        {error_message}
        </mensagem_de_erro_sql>

        <pergunta_usuario_original>
        {user_question}
        </pergunta_usuario_original>

        Instru√ß√µes de Corre√ß√£o:
        1.  Analise o <mensagem_de_erro_sql> e o <contexto_schema>.
        2.  O erro √© provavelmente um nome de coluna ou tabela incorreto. Use o contexto para encontrar o nome correto.
        3.  Responda APENAS com o c√≥digo SQL corrigido, sem explica√ß√µes.

        SQL Corrigido:
        """
    else:
        # Modo padr√£o "GERA√á√ÉO"
        prompt = f"""
        Voc√™ √© um especialista em gerar c√≥digo T-SQL para SQL Server.
        Sua tarefa √© gerar uma √öNICA query SQL v√°lida baseada na pergunta do usu√°rio e no contexto do schema fornecido.

        <instru√ß√µes>
        1.  Use APENAS as tabelas e colunas descritas no contexto.
        2.  Preste aten√ß√£o especial √†s se√ß√µes de RELACIONAMENTOS para criar JOINs corretos.
        3.  Responda APENAS com o c√≥digo SQL, sem explica√ß√µes ou formata√ß√£o ```sql.
        </instru√ß√µes>

        <contexto_schema>
        {relevant_context}
        </contexto_schema>

        <pergunta_usuario>
        {user_question}
        </pergunta_usuario>

        SQL Gerado:
        """

    try:
        response = MODEL.generate_content(prompt)
        sql_query = response.text.strip()
        # Limpeza final
        if sql_query.startswith("```sql"):
            sql_query = sql_query[6:]
        if sql_query.endswith("```"):
            sql_query = sql_query[:-3]
        return sql_query.strip()
    except Exception as e:
        print(f"‚ùå Erro na API Gemini (generate_sql): {str(e)}")
        return "SELECT 'Erro ao gerar SQL' AS Error;"

# ==============================================================================
# üîπ CAMADA DE SEGURAN√áA (ATUALIZADA)
# ==============================================================================

def generate_safe_sql(user_question, relevant_context, failed_sql=None, error_message=None):
    # Passa todos os argumentos para a fun√ß√£o de gera√ß√£o
    raw_sql = generate_sql(user_question, relevant_context, failed_sql, error_message)

    # Regras de seguran√ßa s√£o aplicadas em AMBAS as gera√ß√µes (inicial e corre√ß√£o)
    forbidden_keywords = ["DROP", "DELETE", "UPDATE", "INSERT", "TRUNCATE", "ALTER", "CREATE", "EXEC"]
    for keyword in forbidden_keywords:
        if keyword in raw_sql.upper():
            print(f"‚ö†Ô∏è ALERTA DE SEGURAN√áA: SQL bloqueado por conter '{keyword}': {raw_sql}")
            return "SELECT 'Comando n√£o permitido detectado.' AS SecurityError;"

    # For√ßar TOP 1000 apenas se n√£o for uma corre√ß√£o (corre√ß√µes podem j√° t√™-lo)
    if not failed_sql and "SELECT" in raw_sql.upper() and "LIMIT" not in raw_sql.upper() and "TOP" not in raw_sql.upper():
        raw_sql = raw_sql.replace("SELECT", "SELECT TOP 1000", 1)
        print("üõ°Ô∏è Adicionado 'TOP 1000' por seguran√ßa √† query.")

    return raw_sql


# ==============================================================================
# üîπ EXECUTAR SQL LOCALMENTE (ATUALIZADO PARA RETORNAR ERRO)
# ==============================================================================
def execute_sql(sql_query):
    try:
        df = pd.read_sql(sql_query, engine)
        
        if len(df) > 50:
             json_results = df.head(50).to_json(orient='records', indent=2) + f"\n... (resultados truncados, mostrando 50 de {len(df)} registros)"
        else:
             json_results = df.to_json(orient='records', indent=2)
        
        # Sucesso: Retorna os resultados e None para o erro
        return json_results, None
    except Exception as e:
        # Falha: Retorna None para os resultados e a string do erro
        error_message = str(e)
        print(f"‚ùå Erro ao executar SQL: {error_message}")
        return None, error_message

# ==============================================================================
# üîπ TRATAR RESPOSTA COM GEMINI (ATUALIZADO COM GLOSS√ÅRIO)
# ==============================================================================
def treat_response(sql_results, user_question, schema_context):
    if len(sql_results) > 1500:
        sql_results = sql_results[:1500] + "\n... (dados truncados)"
        
    if len(schema_context) > 1000:
        schema_context = schema_context[:1000] + "\n... (gloss√°rio truncado)"

    prompt = f"""
    Com base nos dados JSON, responda √† pergunta do usu√°rio.
    Use o "Gloss√°rio" para entender o significado das colunas e explicar a resposta corretamente em portugu√™s.

    <glossario_de_dados>
    {schema_context}
    (Ex: 'gross_monthly_median' √© a mediana do sal√°rio mensal bruto.)
    </glossario_de_dados>

    <dados_json>
    {sql_results}
    </dados_json>

    <pergunta_original>
    {user_question}
    </pergunta_original>

    Instru√ß√µes da Resposta:
    - Responda de forma clara e concisa.
    - Use o gloss√°rio para explicar os termos t√©cnicos (ex: "A mediana do sal√°rio bruto (gross_monthly_median) foi...").
    - Se houver uma mensagem de erro nos dados, explique o erro de forma amig√°vel.
    - N√£o mencione JSON ou SQL.

    Resposta final:
    """
    try:
        response = MODEL.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print(f"‚ùå Erro na API Gemini (treat_response): {str(e)}")
        return f"Houve um problema ao processar os resultados. Dados brutos: {sql_results}"


# ===========================
# üîπ ARMAZENAR HIST√ìRICO
# ===========================
def store_history(user_question, sql_query):
    history_doc = f"Pergunta: {user_question}\nSQL: {sql_query}"
    history_id = f"query_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
    history_collection.add(documents=[history_doc], ids=[history_id])
    print(f"üß† Hist√≥rico salvo (ID: {history_id})")

# ===========================
# üîπ FUN√á√ÉO AUXILIAR PARA MEDIR TEMPO
# ===========================
def time_it(func, *args, **kwargs):
    start = time.perf_counter()
    result = func(*args, **kwargs)
    elapsed = time.perf_counter() - start
    print(f"‚è±Ô∏è  {func.__name__:<25} levou {elapsed:.2f}s")
    return result

# ==============================================================================
# üîπ PIPELINE PRINCIPAL RAG (COM LOOP DE AUTO-CORRE√á√ÉO)
# ==============================================================================

def rag_pipeline(user_question):
    print("\n" + "="*50)
    print(f"üöÄ Iniciando pipeline para a pergunta: '{user_question}'")
    print("="*50)

    # 1. Consultar RAG e verificar cache.
    # 'relevant_context' sempre conter√° o schema para o 'Gloss√°rio'.
    relevant_context, cached_sql = time_it(query_rag_with_cache, user_question)

    if cached_sql:
        print("‚ö° Cache Sem√¢ntico Ativado! Reutilizando SQL.")
        sql_query = cached_sql
    else:
        print("üß† Cache n√£o ativado. Gerando novo SQL com seguran√ßa.")
        # 2. Gerar SQL de forma segura
        sql_query = time_it(generate_safe_sql, user_question, relevant_context)

    print(f"üí¨ SQL (Tentativa 1): {sql_query}")

    # 3. Executar SQL (Tentativa 1)
    results, error = time_it(execute_sql, sql_query)

    # 4. LOOP DE AUTO-CORRE√á√ÉO
    if error:
        print(f"‚ö†Ô∏è SQL (Tentativa 1) falhou: {error}")
        print("üîÑ Iniciando tentativa de auto-corre√ß√£o...")
        
        # Tenta gerar um SQL corrigido
        sql_query = time_it(
            generate_safe_sql,
            user_question,
            relevant_context,
            failed_sql=sql_query,
            error_message=error
        )
        
        print(f"üí¨ SQL (Tentativa 2 - Corrigido): {sql_query}")
        
        # 5. Executar SQL (Tentativa 2)
        results, error = time_it(execute_sql, sql_query)
        
        # 6. Se falhar novamente, desiste e passa o erro para o usu√°rio
        if error:
            print(f"‚ùå Auto-corre√ß√£o falhou: {error}")
            results = json.dumps({
                "error": f"Falha ao executar a query corrigida. Erro: {error}",
                "sql_tentada": sql_query
            }, indent=2)

    # 7. Tratar resposta para o usu√°rio (agora com o gloss√°rio)
    # 'relevant_context' √© o 'schema_relevant' do RAG
    final_answer = time_it(treat_response, results, user_question, relevant_context)

    # 8. Salvar no hist√≥rico apenas se for novo, bem-sucedido e n√£o do cache
    if not cached_sql and not error:
        time_it(store_history, user_question, sql_query)
    
    return final_answer

# ===========================
# üîπ EXECU√á√ÉO DE EXEMPLO
# ===========================

if __name__ == "__main__":
    populate_chroma()

    # --- TESTE 1: Pergunta que requer um JOIN ---
    question1 = "Quais os 5 modelos mais entregues pela operadora EntregaGlobal no Brasil?"
    answer1 = rag_pipeline(question1)
    print(f"\n‚úÖ Resposta Final 1:\n{answer1}")

    # --- TESTE 2: Pergunta que usa o gloss√°rio ---
    question2 = "Qual universidade teve a maior gross_monthly_median em 2019?"
    answer2 = rag_pipeline(question2)
    print(f"\n‚úÖ Resposta Final 2:\n{answer2}")
    
    # --- TESTE 3: Teste de CACHE SEM√ÇNTICO ---
    question3 = "qual a universidade com maior salario bruto mediano em 2019?"
    answer3 = rag_pipeline(question3)
    print(f"\n‚úÖ Resposta Final 3 (do cache):\n{answer3}")
    
    # --- TESTE 4: Teste de AUTO-CORRE√á√ÉO DE SQL ---
    # Pergunta com nome de coluna errado ('employ_rate' em vez de 'employment_rate_overall')
    # Isso deve for√ßar a falha do SQL e ativar o loop de corre√ß√£o.
    question4 = "Qual o 'employ_rate' m√©dio da universidade NUS?"
    answer4 = rag_pipeline(question4)
    print(f"\n‚úÖ Resposta Final 4 (Auto-Corrigida):\n{answer4}")
