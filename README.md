# Pipeline RAG para Consulta em Banco de Dados SQL Server

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) [![Made with ‚ù§Ô∏è by Emily](https://img.shields.io/badge/Made%20with-‚ù§Ô∏è-red)](https://github.com/emily-nicole)

## üìñ Introdu√ß√£o

Este reposit√≥rio cont√©m um **pipeline de Retrieval-Augmented Generation (RAG)** em Python para responder perguntas em linguagem natural sobre dados armazenados em um banco de dados **SQL Server local**. O sistema usa **ChromaDB** com **embeddings TF-IDF locais** (100% offline) para recuperar metadados do schema (tabelas e colunas), permitindo que uma LLM (Google Gemini, gratuita via API) gere consultas SQL precisas, execute-as no banco e retorne respostas tratadas em portugu√™s.

### Funcionalidades Principais
- **RAG Local**: Busca schema relevante sem internet (usa scikit-learn para TF-IDF).
- **Gera√ß√£o de SQL**: LLM mapeia perguntas para SQL, lidando com varia√ß√µes lingu√≠sticas (ex: "Fran√ßa" ‚Üí "France").
- **Execu√ß√£o Segura**: Conecta ao SQL Server via pyodbc (Windows Auth).
- **Hist√≥rico Conversacional**: Armazena perguntas/respostas no RAG para contexto em intera√ß√µes futuras.
- **Tratamento de Respostas**: LLM formata resultados em texto amig√°vel.
- **Escal√°vel e Leve**: Suporta at√© ~1.000-10.000 entradas de hist√≥rico sem lentid√£o (veja [Otimiza√ß√£o](#-otimiza√ß√£o-e-limites)).

**Exemplo de Uso**:
- Pergunta: "Qual o pa√≠s com mais entregas em an√°lise?"
- Resposta: "O pa√≠s com mais entregas em an√°lise √© o Brasil, com 15 registros."

### Arquitetura
```
Usu√°rio ‚Üí Pergunta ‚Üí [RAG: Schema + Hist√≥rico] ‚Üí LLM (SQL) ‚Üí Execu√ß√£o SQL ‚Üí LLM (Resposta) ‚Üí Armazenar Hist√≥rico
```

- **RAG**: ChromaDB (vetor DB persistente).
- **LLM**: Gemini API (gratuita).
- **DB**: SQL Server local (`datasets`).

## üöÄ Instala√ß√£o

### Pr√©-requisitos
- **Python 3.8+**: [Baixe aqui](https://www.python.org/downloads/).
- **SQL Server Local**: Server `EMILYNICOLE`, DB `datasets` (Windows Auth). Teste conex√£o via SSMS.
- **Ambiente Virtual**: Recomendado (ex: `python -m venv .venv; source .venv/bin/activate` no Linux/Mac ou `.venv\Scripts\activate` no Windows).
- **Driver ODBC**: Instale [ODBC Driver 17 for SQL Server](https://docs.microsoft.com/en-us/sql/connect/odbc/download-odbc-driver-for-sql-server).

### Passos
1. Clone o reposit√≥rio:
   ```
   git clone <seu-repo-url>
   cd chatbot
   ```

2. Instale depend√™ncias:
   ```
   pip install chromadb scikit-learn pyodbc google-generativeai pandas python-dotenv
   ```

3. Configure a API Gemini:
   - Crie chave gratuita no [Google AI Studio](https://aistudio.google.com/app/apikey).
   - Crie `.env` na raiz:
     ```
     GEMINI_API_KEY=sua-chave-aqui
     ```
   - (Opcional) Defina no terminal: `$env:GEMINI_API_KEY='sua-chave'` (PowerShell).

4. Popule o RAG (rode o script uma vez):
   ```
   python main.py  # Descomente populate_chroma_and_tfidf() no if __name__
   ```

## üìÅ Estrutura do C√≥digo

```
chatbot/
‚îú‚îÄ‚îÄ main.py                  # Script principal com pipeline
‚îú‚îÄ‚îÄ .env                     # Configs (n√£o commite!)
‚îú‚îÄ‚îÄ chroma_db/               # Pasta gerada: ChromaDB persistente
‚îú‚îÄ‚îÄ tfidf_model.pkl          # Vectorizer TF-IDF salvo
‚îî‚îÄ‚îÄ README.md                # Este arquivo
```

### Fun√ß√µes Principais
- **`populate_chroma_and_tfidf()`**: Prepara embeddings TF-IDF e popula schemas no ChromaDB (rode uma vez).
- **`query_rag(user_question)`**: Recupera schema + hist√≥rico relevante via similaridade TF-IDF.
- **`generate_sql(user_question, context)`**: LLM gera SQL com prompt engenheirado (inclui mapeamentos lingu√≠sticos).
- **`execute_sql(sql_query)`**: Executa no SQL Server e retorna JSON.
- **`treat_response(results, question)`**: LLM formata resposta em PT-BR.
- **`store_history(...)`**: Armazena query no hist√≥rico (nova cole√ß√£o).
- **`rag_pipeline(user_question)`**: Fluxo completo (RAG ‚Üí SQL ‚Üí Exec ‚Üí Resposta ‚Üí Hist√≥rico).

### Schema Hardcoded
Em `schema_documents`: Descri√ß√µes de 4 tabelas (TabelaOriginal, nutrition_cf, GraduateEmployment, game_data_all). Expanda adicionando dicts com `id` e `content` (descri√ß√µes ricas com colunas/exemplos).

## üõ†Ô∏è Uso

### Execu√ß√£o B√°sica
1. Rode o script:
   ```
   python main.py
   ```
   - Isso popula o RAG (se n√£o feito) e testa uma pergunta exemplo.

2. Exemplo Interativo (adicione no `if __name__`):
   ```python
   while True:
       question = input("Fa√ßa uma pergunta: ")
       if question.lower() == 'sair':
           break
       answer = rag_pipeline(question)
       print(f"Resposta: {answer}\n")
   ```

### Exemplos de Perguntas
- "Quantos modelos na Fran√ßa?" ‚Üí Gera `SELECT COUNT(*) FROM [dbo].[TabelaOriginal] WHERE [Pa√≠s] = 'France';`.
- "Qual a taxa de emprego em 2023?" ‚Üí Recupera schema de GraduateEmployment.
- "Hist√≥rico": Perguntas sequenciais usam contexto anterior para consist√™ncia.

### Customiza√ß√µes
- **Adicionar Tabelas**: Edite `schema_documents`, rode `populate_chroma_and_tfidf()`.
- **Mapeamentos Lingu√≠sticos**: Expanda no prompt de `generate_sql` (ex: "Alemanha=Germany").
- **Modelo LLM**: Mude `gemini-1.5-flash` para `gemini-1.5-pro` (mais preciso, mas quota limitada).

## üîç Componente RAG: Detalhes T√©cnicos

O RAG √© **100% local** (sem modelos pr√©-treinados ou internet para busca/embeddings).

### Popula√ß√£o (`populate_chroma_and_tfidf`)
- Vetoriza schemas com **TF-IDF** (scikit-learn): Converte texto em vetores baseados em frequ√™ncia de termos.
- Armazena em ChromaDB: `add(documents, embeddings, ids)`.
- Persiste vectorizer em pickle para queries.

### Consulta (`query_rag`)
- Vetoriza pergunta: `vectorizer.transform([question])`.
- Busca paralela: Schemas (top 2) + Hist√≥rico (top 2).
- Similaridade: Cosseno (padr√£o do ChromaDB).
- Retorno: Contexto concatenado para LLM.

### Hist√≥rico (`store_history` e `history_collection`)
- Armazena: Pergunta + SQL + resumo resultados + resposta.
- Embedding: Baseado na pergunta (reusa TF-IDF).
- ID: Timestamp √∫nico.
- Uso: Recuperado em queries futuras para contexto (ex: "Evite erros de mapeamento passados").

### Limites e Otimiza√ß√£o
- **Armazenamento**: ~5-15 KB/entry. Suporta 1k-10k sem lentid√£o.
- **Pruning**: Adicione na `store_history`:
  ```python
  if history_collection.count() > 500:
      all_ids = history_collection.get()['ids']
      old_ids = all_ids[:-100]  # Mant√©m √∫ltimas 100
      history_collection.delete(ids=old_ids)
  ```
- **Performance**: <1s/query para corpus pequeno. Monitore com `print(history_collection.count())`.

## ‚ö†Ô∏è Troubleshooting

| Problema | Causa | Solu√ß√£o |
|----------|-------|---------|
| **dotenv parsing** | `.env` inv√°lido | Verifique sintaxe (sem espa√ßos em `= `). |
| **ChromaDB embeddings error** | Nesting extra | Use c√≥digo atualizado (embeddings direto). |
| **pyodbc ConnectionError** | Driver ausente | Instale ODBC 17; teste `pyodbc.connect(conn_str)`. |
| **Pandas Warning (SQLAlchemy)** | pyodbc n√£o recomendado | Ignore ou migre para SQLAlchemy (`pip install sqlalchemy`). |
| **Gemini API falha** | Chave/quota | Teste chave; verifique [AI Studio](https://aistudio.google.com). |
| **RAG schema errado** | TF-IDF fraco | Enrique√ßa `content` com sin√¥nimos; aumente `n_results=3`. |
| **Hist√≥rico vazio** | Primeira execu√ß√£o | Rode 2+ perguntas; cheque `print(relevant_context)`. |
| **SQL inv√°lido** | Mismatch tabela | Adicione `[dbo].` no prompt exemplo. |


## üìö Refer√™ncias
- [ChromaDB Docs](https://docs.trychroma.com/)
- [Gemini API](https://ai.google.dev/)
- [scikit-learn TF-IDF](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- **Autor**: Emily Nicole.
