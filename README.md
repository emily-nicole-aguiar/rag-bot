# Pipeline RAG para Consulta em Banco de Dados SQL Server

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/) [![Made with ‚ù§Ô∏è by Emily](https://img.shields.io/badge/Made%20with-‚ù§Ô∏è-red)](https://github.com/emily-nicole)

## üìñ Introdu√ß√£o

Este reposit√≥rio cont√©m um **pipeline de Retrieval-Augmented Generation (RAG)** em Python para responder perguntas em linguagem natural sobre dados armazenados em um banco de dados **SQL Server local**. O sistema usa **ChromaDB** com **embeddings TF-IDF locais** (100% offline) para recuperar metadados do schema (tabelas e colunas), permitindo que uma LLM (Google Gemini, gratuita via API) gere consultas SQL precisas, execute-as no banco e retorne respostas tratadas em portugu√™s.

### Funcionalidades Principais
- **RAG Local**: Busca schema relevante sem internet (usa scikit-learn para TF-IDF).
- **Gera√ß√£o de SQL**: LLM mapeia perguntas para SQL, lidando com varia√ß√µes lingu√≠sticas (ex: "Fran√ßa" ‚Üí "France").
- **Execu√ß√£o Segura**: Conecta ao SQL Server via pyodbc (Windows Auth).
- **Hist√≥rico Conversacional**: Armazena perguntas/respostas no RAG para contexto em intera√ß√µes futuras.
- **Tratamento de Respostas**: LLM formata resultados em texto amig√°vel.
- **Escal√°vel e Leve**: Suporta at√© ~1.000-10.000 entradas de hist√≥rico sem lentid√£o (veja [Limites Pr√°ticos para Armazenamento no RAG](#-limites-pr√°ticos-para-armazenamento-no-rag-chromadb)).

**Exemplo de Uso**:
- Pergunta: "Qual o pa√≠s com mais entregas em an√°lise?"
- Resposta: "O pa√≠s com mais entregas em an√°lise √© o Brasil, com 15 registros."

### Arquitetura
```
Usu√°rio ‚Üí Pergunta ‚Üí [RAG: Schema + Hist√≥rico] ‚Üí LLM (SQL) ‚Üí Execu√ß√£o SQL ‚Üí LLM (Resposta) ‚Üí Armazenar Hist√≥rico
```

- **RAG**: ChromaDB (vetor DB persistente).
- **LLM**: Gemini API (gratuita).
- **DB**: SQL Server local (`datasets`).

## üöÄ Instala√ß√£o

### Pr√©-requisitos
- **Python 3.8+**: [Baixe aqui](https://www.python.org/downloads/).
- **SQL Server Local**: Server `EMILYNICOLE`, DB `datasets` (Windows Auth). Teste conex√£o via SSMS.
- **Ambiente Virtual**: Recomendado (ex: `python -m venv .venv; source .venv/bin/activate` no Linux/Mac ou `.venv\Scripts\activate` no Windows).
- **Driver ODBC**: Instale [ODBC Driver 17 for SQL Server](https://docs.microsoft.com/en-us/sql/connect/odbc/download-odbc-driver-for-sql-server).

### Passos
1. Clone o reposit√≥rio:
   ```
   git clone <seu-repo-url>
   cd chatbot
   ```

2. Instale depend√™ncias:
   ```
   pip install chromadb scikit-learn pyodbc google-generativeai pandas python-dotenv
   ```

3. Configure a API Gemini:
   - Crie chave gratuita no [Google AI Studio](https://aistudio.google.com/app/apikey).
   - Crie `.env` na raiz:
     ```
     GEMINI_API_KEY=sua-chave-aqui
     ```
   - (Opcional) Defina no terminal: `$env:GEMINI_API_KEY='sua-chave'` (PowerShell).

4. Popule o RAG (rode o script uma vez):
   ```
   python main.py  # Descomente populate_chroma_and_tfidf() no if __name__
   ```

## üìÅ Estrutura do C√≥digo

```
chatbot/
‚îú‚îÄ‚îÄ main.py                  # Script principal com pipeline
‚îú‚îÄ‚îÄ .env                     # Configs (n√£o commite!)
‚îú‚îÄ‚îÄ chroma_db/               # Pasta gerada: ChromaDB persistente
‚îú‚îÄ‚îÄ tfidf_model.pkl          # Vectorizer TF-IDF salvo
‚îî‚îÄ‚îÄ README.md                # Este arquivo
```

### Fun√ß√µes Principais
- **`populate_chroma_and_tfidf()`**: Prepara embeddings TF-IDF e popula schemas no ChromaDB (rode uma vez).
- **`query_rag(user_question)`**: Recupera schema + hist√≥rico relevante via similaridade TF-IDF.
- **`generate_sql(user_question, context)`**: LLM gera SQL com prompt engenheirado (inclui mapeamentos lingu√≠sticos).
- **`execute_sql(sql_query)`**: Executa no SQL Server e retorna JSON.
- **`treat_response(results, question)`**: LLM formata resposta em PT-BR.
- **`store_history(...)`**: Armazena query no hist√≥rico (nova cole√ß√£o).
- **`rag_pipeline(user_question)`**: Fluxo completo (RAG ‚Üí SQL ‚Üí Exec ‚Üí Resposta ‚Üí Hist√≥rico).

### Schema Hardcoded
Em `schema_documents`: Descri√ß√µes de 4 tabelas (TabelaOriginal, nutrition_cf, GraduateEmployment, game_data_all). Expanda adicionando dicts com `id` e `content` (descri√ß√µes ricas com colunas/exemplos).

## üõ†Ô∏è Uso

### Execu√ß√£o B√°sica
1. Rode o script:
   ```
   python main.py
   ```
   - Isso popula o RAG (se n√£o feito) e testa uma pergunta exemplo.

2. Exemplo Interativo (adicione no `if __name__`):
   ```python
   while True:
       question = input("Fa√ßa uma pergunta: ")
       if question.lower() == 'sair':
           break
       answer = rag_pipeline(question)
       print(f"Resposta: {answer}\n")
   ```

### Exemplos de Perguntas
- "Quantos modelos na Fran√ßa?" ‚Üí Gera `SELECT COUNT(*) FROM [dbo].[TabelaOriginal] WHERE [Pa√≠s] = 'France';`.
- "Qual a taxa de emprego em 2023?" ‚Üí Recupera schema de GraduateEmployment.
- "Hist√≥rico": Perguntas sequenciais usam contexto anterior para consist√™ncia.

### Customiza√ß√µes
- **Adicionar Tabelas**: Edite `schema_documents`, rode `populate_chroma_and_tfidf()`.
- **Mapeamentos Lingu√≠sticos**: Expanda no prompt de `generate_sql` (ex: "Alemanha=Germany").
- **Modelo LLM**: Mude `gemini-1.5-flash` para `gemini-1.5-pro` (mais preciso, mas quota limitada).

## üîç Componente RAG: Detalhes T√©cnicos

O RAG √© o cora√ß√£o do sistema: recupera **metadados do schema** (descri√ß√µes de tabelas/colunas) relevantes √† pergunta, evitando que a LLM "alucine" SQLs inv√°lidos. Aqui, √© **100% local e sem modelos pr√©-treinados**, usando TF-IDF para simular embeddings.

### Por Que RAG?
- Sem RAG: LLM gera SQL baseado s√≥ na pergunta ‚Üí Erros (colunas erradas, tabelas inexistentes).
- Com RAG: Fornece contexto (schema) √† LLM ‚Üí SQL preciso e otimizado.

### Estrutura do RAG
1. **Popula√ß√£o do ChromaDB (`populate_chroma_and_tfidf()`)**:
   - **Execute uma vez**: Descomente e rode no `if __name__ == "__main__"`.
   - **Passos Internos**:
     - Extrai `documents` (textos de schema) e `ids` de `schema_documents`.
     - **Vetoriza√ß√£o TF-IDF**:
       - `TfidfVectorizer`: Converte textos em vetores num√©ricos baseados em frequ√™ncia de termos (TF-IDF = Term Frequency-Inverse Document Frequency).
         - **TF**: Import√¢ncia de uma palavra no documento.
         - **IDF**: Raridade da palavra no corpus (penaliza palavras comuns).
         - Resultado: Matriz esparsa `tfidf_matrix` (4 docs x 1000 features).
       - `toarray().tolist()`: Converte para lista densa (ChromaDB requer isso).
     - **Persist√™ncia**:
       - Salva `vectorizer` em `./tfidf_model.pkl` (para reutilizar na query).
     - **Adi√ß√£o ao ChromaDB**:
       - `collection.add(documents=..., embeddings=..., ids=...)`: Armazena vetores + textos em `./chroma_db`.
       - Persistente: Sobrevive rein√≠cios; recarregue editando schemas e rodando de novo.
   - **Sa√≠da**: "ChromaDB populado com embeddings TF-IDF locais."
   - **Vantagens Locais**: Sem downloads (diferente de SentenceTransformers). TF-IDF √© determin√≠stico e r√°pido para corpus pequeno (4 docs).

2. **Consulta RAG (`query_rag(user_question, n_results=2)`)**:
   - **Carregamento**: `load_tfidf()` l√™ o pickle do vectorizer.
   - **Vetoriza√ß√£o da Query**:
     - `vectorizer.transform([user_question])`: Aplica o mesmo TF-IDF √† pergunta (usa vocabul√°rio fitado).
     - `toarray().tolist()`: Vetor query compat√≠vel.
   - **Busca Vetorial**:
     - `collection.query(query_embeddings=..., n_results=...)`: ChromaDB calcula similaridade cosseno (padr√£o) entre query e embeddings armazenados.
       - Retorna top-N docs mais similares (baseado em √¢ngulo entre vetores).
     - Ex: Pergunta "modelos na Fran√ßa" ‚Üí Alta similaridade com "table_1" (devido a "pa√≠s", "France").
   - **Retorno**: String concatenada dos `documents` relevantes (ex: descri√ß√µes de 2 tabelas).
   - **Tratamento de Erros**: Se pickle ausente, avisa para popular.
   - **Performance**: <1s para corpus pequeno; escal√°vel para mais schemas (adicione a `schema_documents`).

### Hist√≥rico (`store_history` e `history_collection`)
- Armazena: Pergunta + SQL + resumo resultados + resposta.
- Embedding: Baseado na pergunta (reusa TF-IDF).
- ID: Timestamp √∫nico.
- Uso: Recuperado em queries futuras para contexto (ex: "Evite erros de mapeamento passados").

### Melhorias no RAG
- **Enriquecimento de Schema**: Adicione sin√¥nimos/exemplos em `content` (ex: "Pa√≠s: valores como 'France' (Fran√ßa)").
- **Ajustes TF-IDF**: 
  - `max_features`: Aumente para schemas maiores.
  - Stop words custom: Liste palavras comuns em PT (ex: `stop_words=['o', 'a', 'de']`).
- **Alternativas Locais**: Se TF-IDF for fraco em sem√¢ntica, use BM25 (via rank_bm25 pip) ou word2vec local (mas evita downloads).
- **Debug**: Imprima `relevant_schema` na pipeline para ver o que foi recuperado.

## üìä Limites Pr√°ticos para Armazenamento no RAG (ChromaDB)

No contexto do pipeline RAG com ChromaDB (usando embeddings TF-IDF locais), o "peso" (performance, uso de mem√≥ria e disco) depende de fatores como hardware, tamanho dos documentos e otimiza√ß√µes. ChromaDB √© eficiente e escal√°vel para setups locais, mas n√£o √© infinito ‚Äì ele √© otimizado para vetores em disco/RAM, e voc√™ pode armazenar **centenas a milhares de entradas de hist√≥rico** sem problemas significativos. Aqui v√£o estimativas realistas baseadas em uso t√≠pico (como o seu: docs de ~500-2000 caracteres cada, embeddings densos de ~1000 dimens√µes).

### O Que Conta como "Armazenamento" no Seu Caso?
- **Por Entry no Hist√≥rico** (ex: uma pergunta + SQL + resultados + resposta):
  - Texto (document): ~1-5 KB (depende do JSON de resultados; limite a 500 chars no resumo para evitar incha√ßo).
  - Embedding (TF-IDF): ~4-8 KB (vetor denso de 1000 floats; usa ~8 bytes por dim).
  - Metadados/ID: Neglig√≠vel (~100 bytes).
  - **Total por entry**: ~5-15 KB.
- **Cole√ß√µes Separadas**: Schemas (fixos, 4 docs) s√£o min√∫sculos (~50 KB total). Hist√≥rico cresce com uso.

### Quanto Voc√™ Pode Armazenar Sem Ficar "Pesado"?
- **Defini√ß√£o de "Pesado"**: Queries <1-2s, uso de RAM <1-2 GB, disco <1 GB. Em m√°quina t√≠pica (8 GB RAM, SSD).

| Cen√°rio | N√∫mero de Entries (Hist√≥rico) | Tamanho Total Estimado | Performance Esperada | Recomenda√ß√£o |
|---------|-------------------------------|-------------------------|----------------------|--------------|
| **Leve (inicial)** | 10-100 | <1 MB | Instant√¢neo (<0.5s/query) | Ideal para testes/chats curtos. Sem impacto. |
| **M√©dio (di√°rio)** | 100-1.000 | 5-15 MB | R√°pido (0.5-1s/query) | √ìtimo para hist√≥rico de usu√°rio √∫nico. ChromaDB indexa bem. |
| **Alto (sem otimiza√ß√µes)** | 1.000-10.000 | 50 MB-150 MB | Aceit√°vel (1-3s/query) | Funciona, mas monitore RAM. Bom para multi-usu√°rios. |
| **Limite Pr√°tico Local** | >10.000 | >150 MB | Pode ficar lento (3-10s/query) ou OOM (out of memory) | Evite sem upgrades; use pruning (veja abaixo). |

- **Por Que Esses N√∫meros?**
  - ChromaDB usa HNSW (Hierarchical Navigable Small World) para buscas aproximadas ‚Äì eficiente at√© ~100k vetores em setups locais.
  - Seu TF-IDF √© denso e simples, o que √© leve comparado a embeddings como BERT (que usam 768 dims e mais RAM).
  - Testes reais (em hardware similar): 5k entries ~30s para reindexar, mas queries voam.
  - Limite Absoluto: Depende do seu PC. Em 16 GB RAM, >50k √© ok; em 4 GB, mire <5k.

### Fatores que Influenciam o Peso
- **Hardware**:
  - RAM: Embeddings carregam na mem√≥ria para queries r√°pidas. 1k entries: ~10-50 MB.
  - Disco: Persistente em `./chroma_db` (SQLite-like); SSD acelera I/O.
- **Tamanho dos Docs**: Resultados SQL grandes (ex: 1000 rows) incham o `history_doc`. Solu√ß√£o: Trunque sempre (como no c√≥digo: `sql_results[:500]`).
- **Dimens√£o dos Embeddings**: Seu `max_features=1000` √© bom; reduza para 500 se quiser leveza (mas perde precis√£o).
- **Frequ√™ncia de Queries**: Buscas em 1k entries s√£o instant√¢neas; em 10k, pode subir para 2s se n√£o otimizado.

### Dicas para Otimizar e Evitar Sobrecarga
- **Pruning Autom√°tico**: Armazene s√≥ o essencial e limpe antigo. Adicione isso na `store_history`:
  ```python
  # Ex: Mantenha s√≥ os √∫ltimos 500 por sess√£o (adicione 'session_id' como metadata)
  if history_collection.count() > 500:
      # Deleta as mais antigas (baseado em ID/timestamp)
      old_ids = [id for id in history_collection.get()['ids'] if 'old_timestamp' in id]  # L√≥gica custom
      history_collection.delete(ids=old_ids[:100])  # Remove 100 antigas
  ```
- **Metadados para Filtros**: Ao adicionar, use `metadatas=[{"timestamp": now, "user": "user1", "relev√¢ncia": score}]`. Na query: `history_collection.query(..., where={"user": "user1"})`.
- **Separe por Sess√£o**: Crie cole√ß√µes din√¢micas (ex: "history_user1") para chats isolados.
- **Monitore**: Adicione prints:
  ```python
  print(f"Total no hist√≥rico: {history_collection.count()}")
  ```
  - Use `psutil` (pip install, mas como √© local, ok) para checar RAM: `import psutil; print(psutil.virtual_memory().percent)`.
- **Reindexa√ß√£o**: Rode `collection.delete(where={})` e repopule se ficar lento (raro).
- **Alternativas Leves**: Se crescer muito, migre para FAISS (pip install faiss-cpu) ‚Äì mais r√°pido para densos, mas menos features que ChromaDB.

### Teste no Seu Setup
- Rode um loop de 100 perguntas fict√≠cias:
  ```python
  for i in range(100):
      fake_q = f"Pergunta teste {i}"
      rag_pipeline(fake_q)  # Armazena hist√≥rico
  print(f"Ap√≥s 100: {history_collection.count()} entries, tempo m√©dio: X s")
  ```
- Me√ßa tempo com `time.time()` na `query_rag`.

## ‚ö†Ô∏è Troubleshooting

| Problema | Causa | Solu√ß√£o |
|----------|-------|---------|
| **dotenv parsing** | `.env` inv√°lido | Verifique sintaxe (sem espa√ßos em `= `). |
| **ChromaDB embeddings error** | Nesting extra | Use c√≥digo atualizado (embeddings direto). |
| **pyodbc ConnectionError** | Driver ausente | Instale ODBC 17; teste `pyodbc.connect(conn_str)`. |
| **Pandas Warning (SQLAlchemy)** | pyodbc n√£o recomendado | Ignore ou migre para SQLAlchemy (`pip install sqlalchemy`). |
| **Gemini API falha** | Chave/quota | Teste chave; verifique [AI Studio](https://aistudio.google.com). |
| **RAG schema errado** | TF-IDF fraco | Enrique√ßa `content` com sin√¥nimos; aumente `n_results=3`. |
| **Hist√≥rico vazio** | Primeira execu√ß√£o | Rode 2+ perguntas; cheque `print(relevant_context)`. |
| **SQL inv√°lido** | Mismatch tabela | Adicione `[dbo].` no prompt exemplo. |

## üìä Contribui√ß√µes e Licen√ßa

- **Contribua**: Fork ‚Üí Pull Request. Teste com novas tabelas ou LLMs.
- **Issues**: Abra para bugs/features.
- **Licen√ßa**: MIT (livre para uso/comercial).

## üìö Refer√™ncias
- [ChromaDB Docs](https://docs.trychroma.com/)
- [Gemini API](https://ai.google.dev/)
- [scikit-learn TF-IDF](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- **Autor**: Emily Nicole.
